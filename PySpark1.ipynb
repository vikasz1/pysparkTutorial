{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":61029,"status":"ok","timestamp":1723658748577,"user":{"displayName":"Vikas Maury","userId":"05366182623802963751"},"user_tz":-330},"id":"kpfkWQG1DvBQ","outputId":"73d861f2-9a9a-41df-d5d5-6ca5e1eedf00"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hCollecting py4j==0.10.9.7 (from pyspark)\n","  Using cached py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\n","Using cached py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812367 sha256=22a1d7820da4b35f6cfb83fabcc5c835bac522f9fcaad01eae52e67538bacdeb\n","  Stored in directory: /home/vikas-maury/.cache/pip/wheels/cf/c0/b9/f147f4220fd1d9277d0981b88b35b26f03ad910fffd60013a6\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9.7 pyspark-3.5.2\n"]}],"source":["!pip install pyspark\n","pip install pandas"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":405,"status":"ok","timestamp":1723658766361,"user":{"displayName":"Vikas Maury","userId":"05366182623802963751"},"user_tz":-330},"id":"KqNEU-TTEDEz"},"outputs":[],"source":["import  pyspark"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"collapsed":true,"executionInfo":{"elapsed":8,"status":"ok","timestamp":1723658985313,"user":{"displayName":"Vikas Maury","userId":"05366182623802963751"},"user_tz":-330},"id":"Ihv50qY-EKa8","outputId":"8122f814-0e21-4caf-9f1a-9ad26c730cd3"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","      <th>Experience</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Vikas</td>\n","      <td>24</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Adityan</td>\n","      <td>32</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Bhavani</td>\n","      <td>43</td>\n","      <td>15</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Name  Age  Experience\n","0    Vikas   24           0\n","1  Adityan   32           8\n","2  Bhavani   43          15"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","pd.read_csv('sample_data.csv')\n","#"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":7306,"status":"ok","timestamp":1723659084529,"user":{"displayName":"Vikas Maury","userId":"05366182623802963751"},"user_tz":-330},"id":"ntMimI7bFNl2"},"outputs":[{"name":"stderr","output_type":"stream","text":["24/08/15 00:37:29 WARN Utils: Your hostname, vikas-maury-1-0 resolves to a loopback address: 127.0.1.1; using 192.168.1.42 instead (on interface wlp2s0)\n","24/08/15 00:37:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n","Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","24/08/15 00:37:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"]}],"source":["# Create a Pyspark Session\n","from pyspark.sql import SparkSession\n","spark=SparkSession.builder.appName('Practise').getOrCreate()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"collapsed":true,"executionInfo":{"elapsed":411,"status":"ok","timestamp":1723659104479,"user":{"displayName":"Vikas Maury","userId":"05366182623802963751"},"user_tz":-330},"id":"GznDNFJ6Fcms","outputId":"a9409ba3-a0b8-429b-9a6e-a7f534a82bf6"},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://192.168.1.42:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.5.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Practise</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7ec0795c9fd0>"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["spark"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":7332,"status":"ok","timestamp":1723659157899,"user":{"displayName":"Vikas Maury","userId":"05366182623802963751"},"user_tz":-330},"id":"DHSxBXGhFqyV"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+---+----------+\n","|    _c0|_c1|       _c2|\n","+-------+---+----------+\n","|   Name|Age|Experience|\n","|  Vikas| 24|         0|\n","|Adityan| 32|         8|\n","|Bhavani| 43|        15|\n","+-------+---+----------+\n","\n"]}],"source":["df_pyspark=spark.read.csv('sample_data.csv')\n","df_pyspark.show()"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1119,"status":"ok","timestamp":1723659389902,"user":{"displayName":"Vikas Maury","userId":"05366182623802963751"},"user_tz":-330},"id":"o2pftdGEF2IG","outputId":"622dc20b-78b8-4e12-8bd6-216a7bac4c2b"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+---+----------+\n","|   Name|Age|Experience|\n","+-------+---+----------+\n","|  Vikas| 24|         0|\n","|Adityan| 32|         8|\n","|Bhavani| 43|        15|\n","+-------+---+----------+\n","\n"]}],"source":["df_pyspark = spark.read.option('header','true').csv(\"sample_data.csv\")\n","df_pyspark.show()"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":416,"status":"ok","timestamp":1723659395002,"user":{"displayName":"Vikas Maury","userId":"05366182623802963751"},"user_tz":-330},"id":"VmDgHZt8GoAz","outputId":"661a7629-9016-4469-8a37-dec987f7444f"},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- Name: string (nullable = true)\n"," |-- Age: string (nullable = true)\n"," |-- Experience: string (nullable = true)\n","\n"]}],"source":["df_pyspark.printSchema()"]},{"cell_type":"markdown","metadata":{"id":"1-MzqyB5HBLQ"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP+Vu58xJcisGJXgQnnsF6I","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":0}
